{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from modules.detect import Detector\n",
    "from modules.classify import Classifier\n",
    "from modules.crop import crop_image\n",
    "\n",
    "import torch\n",
    "#ImageFromVideo.get_image('data/video/2023032319.mov')\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "import requests\n",
    "# Initialize a class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  aab8e04 torch 1.12.1 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192.0MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 306 layers, 36905341 parameters, 36905341 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "human_detector = Detector()\n",
    "#dumping_classifier = Classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Capture():\n",
    "    \n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    url = \"http://jungyoon.store:8080/tensor\"   \n",
    "    \n",
    "    \n",
    "    cap = cv2.VideoCapture(1)\n",
    "    print(\"width:\", cap.get(3), \"height : \", cap.get(4))\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Camera open failed!\")\n",
    "        exit()\n",
    "    \n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    delay = round(500/fps)\n",
    "    print(\"fps =\" , fps, \"delay = \", delay)\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, fps, (w,h))\n",
    "\n",
    "    if not out.isOpened():\n",
    "        print('File open failed!')\n",
    "        cap.release()\n",
    "        exit()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    detected = False\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            image = cv2.flip(frame, 1)\n",
    "            \n",
    "            if not detected:\n",
    "                with torch.no_grad():\n",
    "                    det = human_detector.detect(image)\n",
    "            \n",
    "                for i, (*xyxy, conf, cls) in enumerate(reversed(det)):\n",
    "                    if cls == 0:\n",
    "                        print(\"human detected\")\n",
    "                        detected = True\n",
    "                        start_time = time.time()\n",
    "                        print(start_time)\n",
    "            \n",
    "            if detected == True:\n",
    "                out.write(image)\n",
    "                                    \n",
    "                current_time = time.time()\n",
    "                elapsed_time = current_time - start_time\n",
    "                if elapsed_time >= 2.0:\n",
    "                    start_time = current_time\n",
    "                    print(\"video saved and reset\")\n",
    "                    out.release()\n",
    "                    out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "                    \n",
    "                    request = {'results' : \"True\"}\n",
    "                    \n",
    "                    data_json = json.dumps(request)\n",
    "                    \n",
    "                    r = requests.post(url, data=data_json, headers=headers)\n",
    "                    \n",
    "                    if r == 200:\n",
    "                        print(\"post succeed\", r.content.decode('utf-8'))\n",
    "                    else:\n",
    "                        print(\"post failed\", r.status_code)\n",
    "                    detected = False\n",
    "            \n",
    "            cv2.imshow(\"VIDEO\", image)\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 640.0 height :  480.0\n",
      "fps = 30.0 delay =  17\n",
      "human detected\n",
      "1693287882.1614149\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287884.2264478\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287886.2871125\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287888.3762195\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287890.4856532\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287892.578293\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287894.6595874\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287896.7533405\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287898.8205068\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287900.8978467\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287902.977379\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287905.0426621\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287907.1222708\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287909.2137787\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287911.2727716\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287913.3948836\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287915.4752855\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287917.535635\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287919.6200297\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287922.417968\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287924.503689\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287926.6506968\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287928.7403376\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287930.8177345\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287934.3079667\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287936.3891191\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287945.688599\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287947.7645724\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287957.784855\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287959.8591976\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287961.9563897\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287966.188661\n",
      "video saved and reset\n",
      "human detected\n",
      "1693287968.2731388\n"
     ]
    }
   ],
   "source": [
    "Capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
