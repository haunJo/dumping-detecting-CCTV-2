{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import winsound as sd\n",
    "import threading\n",
    "from modules.detect import Detector\n",
    "from modules.crop import crop_image\n",
    "\n",
    "import torch\n",
    "#ImageFromVideo.get_image('data/video/2023032319.mov')\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "import requests\n",
    "# Initialize a class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  31daac8 torch 1.12.1 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192.0MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 306 layers, 36905341 parameters, 36905341 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "human_detector = Detector()\n",
    "#dumping_classifier = Classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Capture():\n",
    "    \n",
    "    cap = cv2.VideoCapture(1)\n",
    "    print(\"width:\", cap.get(3), \"height : \", cap.get(4))\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Camera open failed!\")\n",
    "        exit()\n",
    "    \n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    delay = round(1000/fps)\n",
    "    print(\"fps =\" , fps, \"delay = \", delay)\n",
    "    out = cv2.VideoWriter('../action/output1.mp4', fourcc, fps, (w,h))\n",
    "\n",
    "    if not out.isOpened():\n",
    "        print('File open failed!')\n",
    "        cap.release()\n",
    "        exit()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    detected = False\n",
    "    filenum = 'output1.mp4'\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            image = cv2.flip(frame, 1)\n",
    "            \n",
    "            if not detected:\n",
    "                with torch.no_grad():\n",
    "                    det = human_detector.detect(image)\n",
    "            \n",
    "                for i, (*xyxy, conf, cls) in enumerate(reversed(det)):\n",
    "                    if cls == 0:\n",
    "                        print(\"human detected\")\n",
    "                        detected = True\n",
    "                        start_time = time.time()\n",
    "                        print(start_time)\n",
    "            \n",
    "            if detected == True:\n",
    "                out.write(image)\n",
    "                                    \n",
    "                current_time = time.time()\n",
    "                elapsed_time = current_time - start_time\n",
    "                if elapsed_time >= 2.0:\n",
    "                    start_time = current_time\n",
    "                    print(\"video saved and reset\")\n",
    "                    out.release()\n",
    "                    \n",
    "                    request = threading.Thread(target=send_request, args=filenum[6])\n",
    "                    request.start()\n",
    "                \n",
    "                    if filenum == 'output1.mp4':\n",
    "                        out = cv2.VideoWriter('../action/output2.mp4', fourcc, fps, (w,h))\n",
    "                        filenum = 'output2.mp4'\n",
    "                    elif filenum == 'output2.mp4':\n",
    "                        out = cv2.VideoWriter('../action/output1.mp4', fourcc, fps, (w,h))\n",
    "                        filenum = 'output1.mp4'\n",
    "                        \n",
    "                    detected = False\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            cv2.imshow(\"VIDEO\", image)\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "def send_request(filenum):\n",
    "    request = {'filenum' : f'output{filenum}.mp4'}\n",
    "    \n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    url = \"http://localhost:8080/tensor\" \n",
    "                    \n",
    "    data_json = json.dumps(request)\n",
    "                    \n",
    "    r = requests.post(url, data=data_json, headers=headers)\n",
    "                    \n",
    "    if r.status_code == 200:\n",
    "        print(\"post succeed\", r.content.decode('utf-8'))\n",
    "    else:\n",
    "        print(\"post failed\", r.status_code)\n",
    "    return\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 640.0 height :  480.0\n",
      "fps = 30.0 delay =  33\n",
      "human detected\n",
      "1693409693.1683679\n",
      "video saved and reset\n",
      "post succeed {\"dumping\": 0.6503480076789856, \"walking\": 0.3496519923210144}\n",
      "human detected\n",
      "1693409703.5077045\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409705.5671353\n",
      "video saved and reset\n",
      "post succeed {\"dumping\": 0.5783114433288574, \"walking\": 0.42168858647346497}\n",
      "human detected\n",
      "1693409708.431386\n",
      "post succeed {\"dumping\": 0.811511218547821, \"walking\": 0.18848875164985657}\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409710.4997225\n",
      "video saved and reset\n",
      "post succeed {\"dumping\": 0.704838752746582, \"walking\": 0.29516127705574036}\n",
      "human detected\n",
      "1693409713.8941429\n",
      "post succeed {\"dumping\": 0.3099752962589264, \"walking\": 0.6900246739387512}\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409715.9659142\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409718.0377336\n",
      "post succeed {\"dumping\": 0.23064720630645752, \"walking\": 0.7693528532981873}\n",
      "video saved and reset\n",
      "post succeed {\"dumping\": 0.08949911594390869, \"walking\": 0.9105008244514465}\n",
      "human detected\n",
      "1693409721.9843416\n",
      "post succeed {\"dumping\": 0.7420725226402283, \"walking\": 0.2579275071620941}\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409724.0608587\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409726.4869065\n",
      "post succeed {\"dumping\": 0.8913083076477051, \"walking\": 0.10869163274765015}\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409728.566933\n",
      "post succeed {\"dumping\": 0.45369628071784973, \"walking\": 0.5463037490844727}\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409730.6290903\n",
      "post succeed {\"dumping\": 0.6963593363761902, \"walking\": 0.3036406338214874}\n",
      "video saved and reset\n",
      "post succeed {\"dumping\": 0.7679438591003418, \"walking\": 0.2320561408996582}\n",
      "post succeed {\"dumping\": 0.8955259323120117, \"walking\": 0.10447411239147186}\n",
      "human detected\n",
      "1693409740.4001136\n",
      "video saved and reset\n",
      "human detected\n",
      "1693409742.4600627\n",
      "video saved and reset\n",
      "post succeed {\"dumping\": 0.9925127029418945, \"walking\": 0.007487292867153883}\n",
      "post succeed {\"dumping\": 0.9431074857711792, \"walking\": 0.056892551481723785}\n"
     ]
    }
   ],
   "source": [
    "Capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
